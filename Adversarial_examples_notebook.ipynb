{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMVfQwUu0+HvJOM9ceeum+e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Paul-Lez/adversarial_example_gen/blob/main/Adversarial_examples_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The 101s of fooling a neural network\n",
        "\n",
        "In a previous article, I gave a brief introduction to the topic of adversarial robustness in deep learning through examples of weaknesses of models. When it comes to learning about machine learning, nothing beats getting one’s hands dirty, and with this important precept in mind, this article aims to give the uninitiated machine learner a better understanding of adversarial examples, which is one of the hot areas of research in adversarial machine learning. Of course, no explanation is perfect, and ours has its own shortcomings; in particular we assume our reader is familiar with the basic tenets of (supervised) machine learning, including an understanding of backpropagation. \n"
      ],
      "metadata": {
        "id": "RQc18zUu5MzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A bit of theory (1/2): how models learn\n",
        "\n",
        "Before diving into the actual coding, let's begin by understanding some of the theory behind generating adversarial examples. The ideas we shall investigate are in a sense quite simple, and very elegant, in addition to being closely linked with some core concepts in deep learning like gradient descent and backpropagation. For the sake of simplicity, we will focus on image classification, which has the advantage of yielding examples that can easily be visualized.\n",
        "Let’s consider the standard problem of determining what digit has been drawn on a picture. A typical deep learning solution to this would use a Convolutional Neural Network (CNN), taking as inputs some pictures, and outputting a vector whose largest entry will correspond to the digit the model thinks is on the picture. Typically, one would pass this vector through the softmax function to get a vector of numbers between 0 and 1 that are interpreted as a measure of how confident the model is in its predictions. \n",
        "Let’s say the hypothesis function of our CNN is $h$ (this is just a formal way of saying $h$ is the function that takes in pictures as inputs and outputs the vector. Our CNN will of course have certain parameters that need to be tuned, typically written as a vector $\\theta$, and to emphasise this we will sometimes write $h_\\theta$.\n",
        "A the center of the learning process lies the loss function $L$, which gives a measure of how well the model is performing on a piece of data: if $x$ denotes a picture and $y$ denotes its label (0 or 1), $L(h(x), y)$ will be small if the model predicts the right answer confidently and large if the model predicts the wrong answer confidently. \n",
        "For binary classifiers, the standard choice for the loss function is $L(a, b) = a \\log(b) + (1 - a) \\log(1-b)$.\n",
        "\n",
        "Given some (labelled) data $(x_1, y_1), \\dotsc, (x_n, y_n)$, the training process aims to find a value of $\\theta$ that minimises the average loss $$\\frac{1}{m} \\sum_{k=1}^m L(h_\\theta(x_k), y_k),$$ usually by using some variant of gradient descent (usually, when one is dealing with high-dimensional data, as is often the case in deep learning, finding a global minimum would tend to be quite hard, so one tends to settle for a local minimum). As you may recall, the intuition behind gradient descent is that since the negative gradient tells us in which direction the function is decreasing the most, following the negative gradient could lead us to a local minimum. This amounts to doing the following steps\n",
        "\n",
        "1.   Compute the gradient $G := \\nabla_\\theta \\frac{1}{m} \\sum_{k=1}^m L(h_\\theta(x_k), y_k) $.\n",
        "2.   Update the weights: $\\theta \\leftarrow \\theta - \\alpha \\cdot G$.\n",
        "\n",
        "\n",
        "on repeat until we think we have (almost) reached a (local) minimum."
      ],
      "metadata": {
        "id": "ODxNfjdBKn01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define leNet5 model and training process\n",
        "\n",
        "from torch import nn\n",
        "import torch \n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image, ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "from os.path import exists\n",
        "import numpy as np\n",
        "\n",
        "class leNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(leNet, self).__init__()\n",
        "        self.conv_layers = nn.Sequential( \n",
        "            nn.Conv2d(1, 6, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Conv2d(6, 16, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Conv2d(16, 120, 4),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.fully_connected_layers = nn.Sequential(\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, 10),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        y = x.view((x.shape[0], x.shape[1]))   #flatten x \n",
        "        return self.fully_connected_layers(y)\n",
        "\n",
        "#This function trains a leNet model for n_epochs using mini-batch gradient \n",
        "#descent with batches of size batch_size\n",
        "def train_leNet(batch_size, n_epochs): \n",
        "    #batch_size needs to be at least 2 otherwise training breaks \n",
        "\n",
        "    #prepare data\n",
        "    transform = transforms.ToTensor()\n",
        "    training_set = torchvision.datasets.MNIST(root='./data', train=True, \n",
        "                                            download=True, transform=transform)\n",
        "    loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, \n",
        "                                          shuffle=True)\n",
        "\n",
        "    #initialize model, loss and optimiser\n",
        "    model = leNet()\n",
        "    model.train()\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = .001, momentum = .9)\n",
        "\n",
        "    #train model using mini-batch gradient descent \n",
        "    for epoch in range(0, n_epochs):\n",
        "        running_loss = 0\n",
        "        for i, data in enumerate(loader, 0):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pt, lbl = data\n",
        "\n",
        "            output = model.forward(pt)\n",
        "\n",
        "            loss = loss_fn(output, lbl.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "                running_loss = 0.0 \n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "    #output model\n",
        "    return model"
      ],
      "metadata": {
        "id": "oafDv0VyHzyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code itializes a model by either running the previous training function or loading pretrained weights (weights can be found in [the repo](https://github.com/Paul-Lez/adversarial_example_gen)). The computations we will be doing in the sequel depend on the weights, so feel free to experiment with different ones. "
      ],
      "metadata": {
        "id": "Q6gWKHaULBlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = leNet()                               \n",
        "path_leNet =  './weights_leNet.pth'\n",
        "#check if a pre-trained model exists, if not, train a new model\n",
        "if exists(path_leNet):                     \n",
        "    print(\"Loading pretrained model\")\n",
        "    model.load_state_dict(torch.load(path_leNet))\n",
        "else:\n",
        "    print(\"Did not find pretrained model. Training a model instead.\")\n",
        "    model = train_leNet(4, 2)\n",
        "    torch.save(model.state_dict(), path_leNet)\n",
        "\n",
        "model.eval()       "
      ],
      "metadata": {
        "id": "BvFWpYUYLA2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A bit of theory (2/2): generating an adversarial example\n",
        "\n",
        "Typically one might have a picture that one wants to fool the classifier with. For instance we might have an image $x$ with a 3 on it, and our (evil) goal is to fool the model into classifying it as picture with a 4 (or, to make our life easier, any digit except for 3 - there are ways to make fool a model into yielding some specific output, but we will focus on the easier case of fooling a model into outputting any wrong answer) on it. To do so, we will have to modify slightly the image, which corresponds to adding a small perturbation $\\delta$ to $x$. Hence, our goal is to find $\\delta$ such that $x+\\delta$ has the same class as $x$, but gets misclassified by the model.\n",
        "Ideally, $x+\\delta$ should be *virtually* impossible to distinguish from $x$ at first glance (of at least, the pictures should be relatively simimar), i.e. $\\delta$ should be small. There are different ways we could define a notion of size for $\\delta$, but a common (and very sensible) approach in the context of computer vision is to define the *norm* of $\\delta$ as  \n",
        "\n",
        "$$\n",
        "||\\delta||_\\infty = \\max_i |\\delta_i|.\n",
        "$$\n",
        "\n",
        "Thinking of $\\delta$ as a perturbation to our original picture, $||\\delta||_\\infty$ is just the maximal change in pixel value caused by $\\delta$ when we add it to $x$, so that if $||\\delta||_\\infty$ is small, then $x+\\delta$ will look very similar to $x$, since each pixel will only be changed by a small amount. \n",
        "\n",
        "\n",
        "Putting everything together, we can frame the problem of finding $\\delta$ as the following optimization problem: \n",
        "\n",
        "$$\n",
        "\\text{Find } \\delta \\text{ that maximizes } L(h(x+\\delta), y), \\ \\text {subject to } ||\\delta||_\\infty \\le \\varepsilon,\n",
        "$$\n",
        "\n",
        "where $\\varepsilon$ is some small number chosen beforehand (in practice, one would probably have to try multiple values of $\\epsilon$ to ensure that $x+\\delta$ looks like $x$). This puts us in good shape since gradient descent gives us a rather reliable way of solving such optimisation problems (strictly speaking, gradient descent only works for minimization problems, so we should say \"minimize $-L(h(x+\\delta), y)$\" instead of\n",
        "\"maximize $L(x+\\delta, y)$\" - the two are equivalent anyway), with the caveat that we have an extra condition on the variable we are trying to optimize for: $\\lvert \\lvert \\delta \\rvert \\rvert_\\infty$. Fortunately this isn't a real problem: smart people have already thought about this and there is a variant of gradient descent in this setting, namely *projected gradient descent*. Without going into to much detail, this amounts to \"doing standard gradient descent\", but at every step pruning the updated $\\delta$ to make it fit the constraint $|| \\delta ||_\\infty \\le \\epsilon$, i.e. we make the entries of $\\delta$ smaller so that $| \\delta_i | \\le \\varepsilon$ for all $i$ (a small note for the *cognoscenti*: this is where the word projection comes from; the pruning process amounts to projecting $\\delta$ onto the $\\ell_\\infty$ closed ball of radius $\\varepsilon$ around 0\", if you are familiar with this terminology). More explicitly, we just need to do the following \n",
        "1. Compute the gradient $G := \\nabla_\\delta L(h_\\theta(x + \\delta), y) $.\n",
        "2. Update the perturbation: $\\delta \\leftarrow \\delta - \\alpha \\cdot G$.\n",
        "3. Project: for each $i$ such that $|\\delta_i| > \\varepsilon$, replace $\\delta_i$ by $\\varepsilon \\ \\text{sign}(\\delta_i)$.\n",
        "\n",
        "on repeat until we get (close enough) to a local minimum. \n",
        "\n"
      ],
      "metadata": {
        "id": "V0WTT9Dl8D6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code preprocesses the picture we're going to use for generating an adversarial example. \n",
        "To get a feel for what's happening here, it's worth experimenting with other pictures (you can find 2 more on the repo, and many more on the internet - otherwise just make your own using paint)"
      ],
      "metadata": {
        "id": "8APzDf209-1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepares the picture \"5_pic.png\" for generating an adversarial example, \n",
        "# and displays it (don't forget to upload the picture when running the notebook \n",
        "# -- you can find it in the repo).\n",
        "\n",
        "pic = ImageOps.grayscale(Image.open(\"5_pic.png\"))  \n",
        "pic = pic.resize((28,28))\n",
        "pic = ImageOps.invert(pic)\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "   transforms.Resize(28),\n",
        "   transforms.ToTensor(),\n",
        "])\n",
        "pic_tensor = preprocess(pic)[None,:,:,:]\n",
        "\n",
        "\n",
        "#display picture\n",
        "plt.imshow(np.reshape(pic_tensor[0].numpy().transpose(1,2,0), (28,28)), cmap = 'Greys')\n",
        "plt.show(block=True)                         "
      ],
      "metadata": {
        "id": "AkuMK0boIKtc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "557fece5-0220-4962-a961-7161d894019a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finding the adversarial perturbation\n",
        "\n",
        "To find an adversarial example, we find a perturbation `delta` with norm smaller than the variable `eps`. To find this delta, we use projected gradient descent, which, as you may remember, consists of the following steps: \n",
        "\n",
        "\n",
        "1.   Compute the gradient of the loss with respect to `delta`\n",
        "2.   Update `delta`\n",
        "3.   Project `delta` (i.e. make all entries of `delta` smaller than `eps`)\n",
        "\n",
        "This process is very similar to how one usually trains a model. In fact, you should compare this to the code used to train our leNet5 model, and note that the only substantial differences is the projection step - and of course the fact that we are optimising with respect to `delta` instead of the weights of the model.*\n",
        "\n",
        "You should try playing around with the values of `eps` and `n_steps` to see what happens when you make those large/small.\n",
        "\n",
        "Warning: Depending on the picture, and the weights, some (smaller) values of `eps`might not work .\n",
        "\n",
        "*If you looked carefully, you might also have noticed that unlike training, we don't compute `model.forward(x + delta)`. Why? "
      ],
      "metadata": {
        "id": "-yf-5lF-L7ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#first, predict class of picture\n",
        "pic_class = model(pic_tensor).max(dim=1)[1].item()\n",
        "\n",
        "eps = .10                   #size of admissible perturbations\n",
        "delta = torch.zeros_like(pic_tensor, requires_grad=True)\n",
        "opt = torch.optim.SGD([delta], lr=1e-1, momentum=.9)    \n",
        "#run PGD for n_steps \n",
        "n_steps = 60\n",
        "for t in range(n_steps):\n",
        "    pred = model(pic_tensor + delta)\n",
        "    loss = -nn.CrossEntropyLoss()(pred, torch.LongTensor([pic_class]))\n",
        "    if t % 5 == 0:\n",
        "        print(t, loss.item())\n",
        "    \n",
        "    opt.zero_grad()  #set gradient to 0\n",
        "    loss.backward()  #backpropagate to get gradient of the loss with respect to delta\n",
        "    opt.step()       #update delta\n",
        "    delta.data.clamp_(-eps, eps)    #project deta to the l^∞ closed ball of \n",
        "                                    #radius eps around 0\n",
        "\n",
        "\n",
        "#output results\n",
        "pred = model(pic_tensor + delta)\n",
        "max_class = pred.max(dim=1)[1].item()     #class predicted for the last picture \n",
        "\n",
        "print(\"Norm of perturbation is \", delta.max().item())\n",
        "print(\"Predicted digit\", max_class)\n",
        "print(\"Confidence:\", nn.Softmax(dim=1)(pred)[0, max_class].item())\n",
        "\n",
        "plt.imshow(np.reshape((pic_tensor +delta)[0].detach().numpy().transpose(1,2,0),\n",
        "                      (28,28)) , cmap='Greys')\n",
        "plt.show(block=True)"
      ],
      "metadata": {
        "id": "YTqJmzOFL_lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transferability of adversarial attacks \n",
        "\n",
        "To finish up this tutorial, we briefly demonstrate an interesting phenomenon that takes place when working with adversarial examples. By now it should be clear that the process we followed for generating the perturbation is model-specific. More specifically the computation of the gradient of the loss with respect to `delta` depends on the weights of the model. Hence, there is no reason for an adversarial example generated for some model to work on some other model. However, researchers in the field of adversarial machine learning have noticed that this actually happens more frequently than one would expect: this phenomenon is called the transferability of adversarial attacks. \n",
        "\n",
        "From a security point of view, this isn't great: a big practical problem with our approach to finding adversarial examples is that we need a **lot** of information on the model we are trying to fool (namely, its weights) - this is an instance of a *white box attack*. Since the weights of models used in security critical applications are rarely publically available, white-box attacks will necessarily be *rather hard* to pull off. However, the transferability of adversarial attacks opens up new avenues for generating adversarial attacks for models with no information on the actual architecture or weights of the model (a *black box attack*), e.g. by generating adversarial attacks for some known model and using those on the model one wants to fool. See for instance https://arxiv.org/abs/1605.07277.\n",
        "\n"
      ],
      "metadata": {
        "id": "sMMofPSreInf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define slightly different leNet5 model and training process\n",
        "\n",
        "class leNetVariant(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(leNetVariant, self).__init__()\n",
        "        self.conv_layers = nn.Sequential( \n",
        "            nn.Conv2d(1, 6, 5),\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(2, stride=2),\n",
        "            nn.Conv2d(6, 16, 5),\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(2, stride=2),\n",
        "            nn.Conv2d(16, 120, 4),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        self.fully_connected_layers = nn.Sequential(\n",
        "            nn.Linear(120, 84),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(84, 10),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        y = x.view((x.shape[0], x.shape[1]))   #flatten x \n",
        "        return self.fully_connected_layers(y)\n",
        "\n",
        "#This function trains a leNet model for n_epochs using mini-batch gradient \n",
        "#descent with batches of size batch_size\n",
        "def train_leNetVariant(batch_size, n_epochs): \n",
        "    #batch_size needs to be at least 2 otherwise training breaks \n",
        "\n",
        "    #prepare data\n",
        "    transform = transforms.ToTensor()\n",
        "    training_set = torchvision.datasets.MNIST(root='./data', train=True, \n",
        "                                            download=True, transform=transform)\n",
        "    loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, \n",
        "                                          shuffle=True)\n",
        "\n",
        "    #initialize model, loss and optimiser\n",
        "    model = leNetVariant()\n",
        "    model.train()\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = .001, momentum = .9)\n",
        "\n",
        "    #train model using mini-batch gradient descent \n",
        "    for epoch in range(0, n_epochs):\n",
        "        running_loss = 0\n",
        "        for i, data in enumerate(loader, 0):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pt, lbl = data\n",
        "\n",
        "            output = model.forward(pt)\n",
        "\n",
        "            loss = loss_fn(output, lbl.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "                running_loss = 0.0 \n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "    #output model\n",
        "    return model\n",
        "\n",
        "\n",
        "#train the leNet5 variant\n",
        "other_model = leNetVariant()                               \n",
        "path_leNetVariant =  './weights_leNetVariant.pth'\n",
        "#check if a pre-trained model exists, if not, train a new model\n",
        "if exists(path_leNetVariant):                     \n",
        "    print(\"Loading pretrained model\")\n",
        "    other_model.load_state_dict(torch.load(path_leNetVariant))\n",
        "else:\n",
        "    print(\"Did not find pretrained model. Training a model instead.\")\n",
        "    other_model = train_leNetVariant(4, 2)\n",
        "    torch.save(other_model.state_dict(), path_leNetVariant)\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "6a27SwLjjK8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(pic_tensor)\n",
        "max_class = pred.max(dim=1)[1].item()     #class predicted for the last picture \n",
        "\n",
        "print(\"Predicted digit for original pic\", max_class)\n",
        "print(\"Confidence:\", nn.Softmax(dim=1)(pred)[0, max_class].item())\n",
        "\n",
        "pred = model(pic_tensor + delta)\n",
        "max_class = pred.max(dim=1)[1].item()\n",
        "print(\"Predicted digits for modified pic\", max_class)\n",
        "print(\"Confidence:\", nn.Softmax(dim=1)(pred)[0, max_class].item())"
      ],
      "metadata": {
        "id": "odEDwOxIky-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "In this tutorial, we introduced some basic tools for generating adversarial examples and investigated how these connect with the standard supervised learning paradigm, and tested these on a standard machine learning dataset. \n",
        "\n",
        "There are many more ideas in the field of adversarial machine learning that we have not even mentionned so far. For instance, the reader might now be wondering how one goes about strenghtening a model in view of making it more robust to adversarial attacks. This would lead us on to the important the topic of adversarial training, which lies beyond the scope of this article. \n",
        "\n",
        "The interested reader should check out the wonderful tutorial written by Zico Kolter and Aleksander Madry, https://adversarial-ml-tutorial.org/introduction/, to which this tutorial owes a lot. "
      ],
      "metadata": {
        "id": "Ukl5Xwoqmg79"
      }
    }
  ]
}